##########################Projet de Ibrahima et Ziyi########################################
rm(list = ls())
library(ggplot2)
library(forecast)
library(tseries)
library(TSA)

#Soit Xt le processus stationnaire solution de lâ€™Ã©quation:

#                               Xt = 0.4Xtâˆ’1 + Îµt âˆ’ Î¸Îµtâˆ’1,
#  Îµ est un bruit blanc Gaussien de variance 1 et Î¸ = ( moyenne de vos mois de naissance)/13 (vous
#  pouvez arrondir la valeur de Î¸ Ã  2 chiffres aprÃ¨s la virgule).
#  Donc pour nous Theta = (12+4)/13= 1.23

##1. Simuler sous R une rÃ©alisation de longeur n = 200 du processus stationnaire solution de cette
##   Ã©quation. Nommez-le simul.
simul<-arima.sim(list(order=c(1,0,1), ma=-1.23, ar=0.4), n=200)
plot(simul)

##2. Charger les donnÃ©es depuis le fichier â€™data.txtâ€™. Le fichier contient 200 valeurs de la variable x.
##   CrÃ©ez une nouvelle sÃ©rie chronologique comme la somme de x + simul.

###2.1 Chargement les donnÃ©es 
x<- read.csv("data.txt",header = TRUE,sep = " ")
### On utilise le commande "read.csv" pour charger le fichier "data.txt", et le sÃ©parateur entre les donnÃ©es est 
### espace.
x<-ts(x)
plot(x) ## X a une variance qui augmente avec le temps, il est non stationnaire
###2.2 CrÃ©ation la nouvelle sÃ©rie chronologique
serie<-x+ simul

##3. Ajustez le modÃ¨le SARIMA appropriÃ© aux donnÃ©es en suivant les Ã©tapes dÃ©crites dans les diapositives
##   221 et 222 du cours.

###3.1 Tracer la sÃ©rie pour proposer une structure.
plot(serie) ## la variance de la serie augmenta avec le temps, la serie est non stationnaire aussi
#### on peut en deduire que nous avons un modÃ¨le additif. 

###3.2 Tracer l'acf pour dÃ©tecter une tendance ou une composante saisonniÃ¨re.
acf(serie)  

#### Dans la sÃ©rie que nous avons eu, nous pouvons trouver qu'il y a une tendance par l'acf, 
### les memes evenement se repetent par 10 d'ou la pÃ©riode c'est 10.

###3.3 On Ã©limine d'abord la composante saisonniÃ¨re.

####3.3.1 On calcule la pÃ©riode Ã  l'aide des pÃ©riodogrammes
periodog <- function(x, graph = T){
  freqs <- (2 * pi * (0:floor(length(x)/2)))/length(x)
  periodo <- (Mod(fft(x - mean(x)))^2/(2 * pi * length(x)))[1:(floor(length(x)/2) +
                                                                 1)]
  if (graph == T) {
    plot(freqs, periodo, type = "l", main = "Periodogram")
  }
  else {
    return(data.frame(periodo = periodo, freqs = freqs))
  }}
periodog(serie) ##la frequence max (du plus grand pic)= 0.1 alors f=1/n et n= 10
spectrum(serie) ## la periode de la saisonnalité est de 10

####3.3.2 On valide la pÃ©riode r Ã  l'aide du test de saisonnalitÃ©
##### On excute les commandes 


## H0) : pas de saisonnalitÃ© de pÃ©riode r dans la sÃ©rie
## H1) : prÃ©sence d'une saisonnalitÃ© de pÃ©riode r au seuil de alpha=5%

Saison.test <- function(vec, d) {
  n <- length(vec)
  ns <- n%/%d
  n <- ns * d
  vec <- vec[1:n]
  rangs.vec <- matrix(rep(0, n), nrow = d, ncol = ns)
  for (j in 1:ns) {
    saisonj <- vec[(d * (j - 1) + 1):(d * j)]
    rangs.vec[order(saisonj), j] <- 1:d
  }
  rangs <- apply(rangs.vec, 1, sum)
  stat <- 12 * sum((rangs - ns * (d + 1)/2)^2)/(ns * d * (d + 1))
  pval <- 1 - pchisq(stat, df = d - 1)
  res <- c(d, d - 1, stat, pval)
  names(res) <- c("PÂ´eriode", "d.f.", "Tobs", "p-valeur")
  return(res)
}

Saison.test(serie,d=10)
### Le p-valeur est 0 qui est infÃ©rieur Ã  0.05, donc on rejette H0, il y a de la saisonnalitÃ© de pÃ©riode 10 dans 
### la sÃ©rie.

####3.3.3 On diffÃ©rencie la sÃ©rie pour faire disparaÃ®tre la composante saisonniÃ¨re
serie1 <- diff(serie , lag=10)
plot(serie1)

###3.4 On trace de nouveau l'acf pour voir s'il reste une tendance. Si oui, on l'Ã©limine aussi.
acf(serie1)
####3.4.1 On confirme l'existence de la tendance Ã  l'aide des tests des montÃ©es (PtMont.test) 
####      ou des discordances (PtDisc.test).

#### H0) : pas de tendance dans la sÃ©rie
#### H1) : prÃ©sence d'une tendance

##### le test des des discordances


PtDisc.test <- function (vec)
{
  n <- length(vec)
  res <- cor.test(1:n, vec, method="kendall")
  nD=floor((1-res$estimate)/4*n*(n-1))
  Tobs <- ( 1 - 4*nD/(n*(n-1)) ) / sqrt( 2*(2*n+5)/(9*n*(n-1)) )
  p <- 2 * (1- pnorm(abs(Tobs)))
  res <- c(n,nD,Tobs,p)
  names(res) <- c("n","nD","stat"," p-valeur")
  return(res)
}

#### Le rÃ©sultat du test des discordances 
PtDisc.test(serie1)#P-valeur=2.561965e-05  tres petit on rejette Ho presence d'une tendance 

#### Alors dans la sÃ©rie1, nous trouvons que la tendance a  diminue mais,il n'a pas completement disparu donc on va continuer
#### Ã  l'Ã©liminer.

serie2<-( diff(serie1, order=10) )
plot(serie2)

#### Par rapport Ã  la graphique de serie1, le plot de serie2 montre une stationnarité de la serie 2 plus correcte, on peut en conclure
#### qu'il n'y a plus de  tendance dans la sÃ©rie.

####3.4.2 On confirme la disparitiion de la tendance à l'aide des tests des montÃ©es (PtMont.test) 
####      ou des discordances (PtDisc.test).
#### H0) : pas de tendance dans la sÃ©rie
#### H1) : prÃ©sence dâ€™une tendance
####au seuil de alpha=5%
PtMont.test <- function (vec)
{
  n <- length(vec)
  nM <- 0
  for (i in 1:(n-1)){
    if (vec[i] < vec[i+1]) {
      nM <- nM+1         
    }}
  Tobs <- ( nM - (n-1)/2 ) / sqrt( (n+1)/12 )
  p <- 2 * (1- pnorm(abs(Tobs)))
  res <- c(n,nM,Tobs,p)
  names(res) <- c("n","nM","stat"," p-valeur")
  return(res)
}


PtDisc.test <- function (vec)
{
  n <- length(vec)
  res <- cor.test(1:n, vec, method="kendall")
  nD=floor((1-res$estimate)/4*n*(n-1))
  Tobs <- ( 1 - 4*nD/(n*(n-1)) ) / sqrt( 2*(2*n+5)/(9*n*(n-1)) )
  p <- 2 * (1- pnorm(abs(Tobs)))
  res <- c(n,nD,Tobs,p)
  names(res) <- c("n","nD","stat"," p-valeur")
  return(res)
}
#### Le rÃ©sultat du test des montÃ©es
PtMont.test(serie2)#p-valeur = 0.2089124

#### Le rÃ©sultat du test des discordances 
PtDisc.test(serie2)#p-valeur =  0.9102624

###Remarque : Nos p-valeurs changent toujours mais les interpretations
### les memes

#### Dans les 2 rÃ©sultat des 2 test, nous trouvons que les p-valeur tout sont supÃ©rieur Ã  0.05, donc on ne rejette 
#### pas H0, maintenant, il n'y a plus de tendence dans notre serie
acf(serie2)
#### Nous ne trouvons plus de tendance par rapport à l'acf de la derniÃ¨re sÃ©rie(serie1)

## 4. On dÃ©termine le modÃ¨le de la sÃ©rie diffÃ©renciÃ©e.

###4.1 On trace l'acf (acfMA), la pacf et l'eacf pour dÃ©terminer les ordres p et q maximaux.

#### Les commandes pour acfMA
acfMA <- function(x) {
  n <- length(x)
  rho <- acf(x, plot = F)$acf[-1]
  nlags <- length(acf(x, plot = F)$lag)
  wh <- c(1, 1 + 2 * cumsum(rho^2))
  seuilsSup <- 1.96 * sqrt(wh/n)
  seuilsSup <- as.ts(seuilsSup)
  seuilsSup <- ts(seuilsSup, start = 1/frequency(x),
                  end = nlags/frequency(x), frequency = frequency(x))
  acf(x)
  lines(seuilsSup, lty = 2, col = "red",
        lwd = 2)
  lines(-seuilsSup, lty = 2, col = "red",
        lwd = 2)
}
acfMA(serie2)
pacf(serie2)
eacf(serie2)
## P= 0 q = 1 


### 4.2 On estime les coefficients du modÃ¨le SARIMA(p,d,q)(0,1,0)[r] (Arima).

#### Ici on a utilisÃ© la fonction 'auto.arima()' de la package 'forecast' pour choisir le mieux modÃ¨les
modelebien <- auto.arima(serie2);modelebien

#### A preciser qu'à chaque fois qu'on execute tout notre code r, les resulats du auto arima change
### on arrive pas à comprendre pourquoi ???? 
###Par la suite on a gardé le  modÃ¨le ARIMA(4,0,1) qui est avec 0 moyenne.
#### Le rÃ©sultat nous montre que le meilleur modÃ¨les est ARIMA(4,0,1)(1,0,2)[10]

### 4.3 On valide le modÃ¨le avec la commande tsdiag(modele),(les rÃ©sidus doivent former un bruit blanc).
tsdiag(modelebien)
#### on vÃ©rifie que les rÃ©sidus sont bruits blanc par la distributions des rÃ©sidus.
#### et puis dans l'acf des rÃ©sidus, on trouve que aprÃ¨s lag=0,il n'y a pas de autorÃ©gression d'entre eux, c'est Ã 
#### dire que notre modÃ¨les est simulÃ© mieux.

### 4.4 On vÃ©rifie qu'on ne peut pas simplier encore le modÃ¨le.
acf(resid(modelebien))
### 4.5 On effectue des prÃ©visions ( prev(modele) ).

prevmodele <- forecast(modelebien, h = 2)
prevmodele

### 4.6 On vÃ©rifie Si les innovations ( modele$res ) sont gaussiennes.
shapiro.test(modelebien$residuals)#p-value = 0.5287
####H0: Les donnÃ©es de l'Ã©chantillon ne sont pas significativement diffÃ©rentes de la distribution normale.
####H1: les donnÃ©es de l'Ã©chantillon sont trÃ¨s diffÃ©rentes de la distribution normale.

#### Pâ€”valeur est 0.5287, qui est supÃ©rieur Ã  0.05, donc on ne rejette pas H0, donc les innovations suivent la 
#### loi gaussinne.

# Test de normalite jarque.bera.test
jarque.bera.test(serie2)#p-value = 0.987

####H0 : les donnÃ©es suivent une loi normale.
####H1 : les donnÃ©es ne suivent pas une loi normale.
#### Pâ€”valeur est 0.987, qui est supÃ©rieur Ã  0.05, donc on ne rejette pas H0, donc les innovations suivent la 
#### loi gaussinne.

## 5. Estimer les prÃ©visions Ã  lâ€™ordre 1 et 2, i.e., pour X201,X202(avec l'intervalle confiance)
prediction <-forecast(modelebien,h=2,level=c(99.5))
prediction
plot(prediction)

### On prÃ©dit que pour X201, le point Forecast = 0.2054660
###               pour X202, le point Forecast = -0.3511171.(L'intervall confiance est 5%)

